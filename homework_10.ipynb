{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46fee89",
   "metadata": {},
   "source": [
    "# –ó–∞–¥–∞–Ω–∏–µ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c34af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2306f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'gedichte.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a364927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howto\\anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Creating features from dataset file at \n",
      "Saving features into cached file cached_lm_GPT2Tokenizer_64_gedichte.txt [took 0.001 s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "train_dataset = TextDataset( tokenizer=tokenizer,file_path=train_path,block_size=64, \n",
    "                            overwrite_cache=True)\n",
    "  \n",
    "# —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–æ–¥–∞–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω–æ–º –µ–π –≤–∏–¥–µ\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ed55e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments( \n",
    "    output_dir= \"./finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=100, \n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=32,  \n",
    "    gradient_accumulation_steps=16, \n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01521627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 22:58, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.12120740890502929, metrics={'train_runtime': 1392.8561, 'train_samples_per_second': 1.364, 'train_steps_per_second': 0.072, 'total_flos': 62056857600000.0, 'train_loss': 0.12120740890502929, 'epoch': 100.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3ed282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–°–∏—è–µ—Ç –Ω–µ–±–æ –∏ –æ–∑–∞—Ä—è–µ—Ç—Å—è –õ—É–Ω–∞.\n",
      "–ò –∑–≤—ë–∑–¥—ã —Å–≤–µ—Ç—è—Å—å –æ—Ç—Ä–∞–∂–∞—é—Ç –≤—Å—ë –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–µ,\n",
      "–í –ú–∏—Ä —Å–≤–æ–π –ø—Ä–∏—Ö–æ–¥ –æ–∑–∞—Ä—è—è—Å—å –ø–æ–ª–Ω–æ–π —Å–≤—è—Ç–æ—Å—Ç—å—é.\n",
      "\n",
      "–° –¥–æ–±—Ä–æ—Ç–æ–π –¥–µ–ª–∏—Ç—ã–π, —è –∂–∏–ª\n",
      "–í–æ –∑–Ω–æ–π–Ω—ã—Ö —Å—Ç–µ–ø—è—Ö,\n",
      "–í —Å–µ–ª–µ–Ω–∏—è—Ö —é–Ω—ã—Ö,\n",
      "–ò –±—ã–ª–æ —Å–æ –º–Ω–æ–π —Ç–∞–∫ –¥—É—à–µ–≤–Ω–æ,\n",
      "–ß—Ç–æ –º–æ–≥ –±—ã –ø–æ–∂–µ–ª–∞—Ç—å\n",
      "–û —Å–º–µ—Ä—Ç–∏ –¥–∞–∂–µ –Ω–µ–±–æ–∂–µ—Å–∫–∏–π —Ä–æ–¥!\n",
      "\n",
      "–†–∞—Å—Å–∫–∞–∑–∞–ª —è –≤–∞–º —Å–æ–Ω,\n",
      "–î–≤—É–º –¥–µ—Ç–∫–∞–º –Ω–∞ –∑–∞–º–µ—Ç–∫—É –ø—Ä–∏—à–∏—Ç—ã–π\n",
      "–ò –æ—á–µ–Ω—å –µ–º—É –∑–∞—Ü–≤–µ–Ω—è–≤—à–µ–π,\n",
      "–ü–∞–ª–∞—á–µ–π –ø–æ –ø–æ—è—Å.\n",
      "–ü–µ—Ä–≤—ã–π, –∫–∞–∫ –ø–æ–∫–∞–∑–∞–ª–æ—Å—å –≥–ª–∞–∑–∞–º, –∑–∞–º–µ—Ä,\n",
      "–í–∑–¥–æ—Ö–Ω—É–≤ –±–µ–∑ –æ—Ç–¥—ã—Ö–∞. –ï–¥–≤–∞ –∂–∏–≤–æ–π,\n",
      "–ü—Ä–æ–ª–∏–≤—à–∏–π –∫—Ä–æ–≤—å, –≤–∞–ª—è–ª—Å—è —Å—Ç–∞—Ä–∏–∫ –≤–æ –≥—Ä–æ–±—É,\n",
      "–î–≤—É—Ö –¥–µ—Ç–µ–π —É–ª–æ–∂–∏–≤ –Ω–∞–∑–µ–º—å.\n",
      "–í —Ç–æ—Ç –∂–µ –º–∏–≥ —Ä—è–¥—ã—à–∫–æ–º —Å–æ–º–∫–Ω—É–ª—Å—è\n",
      "–†–æ–≥ —Å –≤–æ–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –∫–ª–∏—á–µ–º: \"–íi–¥—ç—Å!\" - –∏ –º—ë—Ä—Ç–≤—ã–º –æ–Ω –≤–ø–æ–ø—ã—Ö–∞—Ö\n",
      "–î–≤–æ–∏—Ö –æ–±–µ–∑–æ–±—Ä–∞–∂–∏–ª —Å—Ç–∞–ª—å—é.\n"
     ]
    }
   ],
   "source": [
    "text = \"–°–∏—è–µ—Ç –Ω–µ–±–æ\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=1.4,\n",
    "                        top_k=50,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4172ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ö–æ–Ω–µ—Ü –ø—É—Ç–∏¬ª. –≠—Ç–æ –æ—Ç—Ä—ã–≤–æ–∫ –∏–∑ –ø–µ—Å–Ω–∏ –û. –£–∞–π–ª—å–¥–∞ \"–ë—Ä–∞—Ç –º–æ–π –ê–ª–µ–∫—Å–µ–π, –Ω–µ –ø–ª–∞—á—å\". –ù–∞ –ø–æ–ª–µ –±–∏—Ç–≤—ã —á–µ–ª–æ–≤–µ–∫ –≤—Å—Ç–∞–µ—Ç –∏ –∏–¥—ë—Ç –∫ –¥–æ–º—É. –ù–∞–≤—Å—Ç—Ä–µ—á—É –µ–º—É ‚Äî –õ–∏–∑–∞, –≤—Å—è –∑–∞–ª—è–ø–∞–Ω–Ω–∞—è –º—É—Ç—å—é. –ù–∞ –∫–æ–ª–µ–Ω—è—Ö —Å—Ç–æ–∏—Ç, –ø—Ä–∏—á–∏—Ç–∞—è –æ–Ω–∞. –°–ø–∏—Ç –æ–Ω–∞ –≤ –∏–∑–±–µ —Ä—è–¥–æ–º —Å –Ω–∏–º. –õ–µ–∂–∞–ª –æ–Ω –æ–¥–∏–Ω, –∫–∞–∫ –º—ë—Ä—Ç–≤—ã–π, –≤ –∏–∑–±–µ. –°–ø–∞–ª–∞ –æ–Ω–∞ –≤ –∏–∑–±–µ, —É –ò–≤–∞–Ω–∞ –í–∞—Å–∏–ª—å–µ–≤–∏—á–∞... –í—Å—ë –∫—Ä—É–≥–æ–º –∑–∞—Ç–∏—Ö–ª–æ... –í—Å—Ç–∞–ª –±–æ–≥–∞—Ç—ã—Ä—å ‚Äî –∏ –≤–∏–¥–∏—Ç: –ø–µ—Ä–µ–¥ –Ω–∏–º–∏ —Å—Ç–æ–∏—Ç –¥–æ–º —Ä–æ–¥–Ω–æ–π. –ó–∞–ø–ª–∞–∫–∞–ª –∏ –æ–±–º–µ—Ä –æ—Ç –∂–∞–ª–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ–∫. –ë—Ä–æ—Å–∏–ª –æ–Ω –∫ –Ω–æ–≥–∞–º —Ü–∞—Ä—å —Ü–∞—Ä–µ–π –¥–∞—Ä—ã: —Ä—É–±–∞—Ö—É –¥–∞ —à—Ç–∞–Ω—ã –æ—Ç–¥–∞–ª, –≤–µ–ª–µ–ª —Å–ª—É–≥–∞–º —Ä—É–±–∏—Ç—å —Å —É–±–∏—Ç—ã—Ö, –¥–∞ –∂–∞—Ä–∏—Ç—å –≤ –ø–µ—á–∏...\n",
      "\n",
      "–ß–µ—Ä–µ–∑ –ª–µ—Å –ø—Ä–æ—à—ë–ª —á–µ–ª–æ–≤–µ–∫ –±–æ–ª—å—à–æ–π ‚Äî –±–æ–ª—å—à–æ–π! ‚Äî –∏ —Å—Ç–∞–ª –∫–æ–ø–∞—Ç—å —è–º—É. –ù–æ –Ω–µ —à–µ–ª–æ—Ö–Ω—É–ª–∏—Å—å —Ä–∞—Å–ø–æ—Ä–æ—Ç—ã–µ –æ–¥–µ–∂–¥—ã. –ò–∑ –∑–µ–º–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏—Å—å –Ω–∞ —Å–≤–µ—Ç —Å—É—Ö–∏–µ —á–µ—Ä–≤–∏. –°—Ç–∞–ª –∑–ª–æ–¥–µ–∏ —Å–æ–≤–æ–∫—É–ø–ª—è—Ç—å—Å—è ‚Äî —á–µ–ª–æ–≤–µ–∫ —Ä—ã–¥–∞–ª –≤—Å—ë –≥—Ä–æ–º—á–µ –∏ —Å–≤–∏—Ä–µ–ø–µ–π. –ù–∞–∫–æ–Ω–µ—Ü,\n"
     ]
    }
   ],
   "source": [
    "text = \"–ö–æ–Ω–µ—Ü –ø—É—Ç–∏\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=1.4,\n",
    "                        top_k=50,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c54060f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–î–æ–∂–¥—å –∏–¥–µ—Ç \n",
      "–ú–µ–∂–¥—É –≥–æ—Ä —Å–µ–¥—ã–º–∏\n",
      "–ò —Ç–∞—é—â–∞—è —Å–∞–≥–∞\n",
      "–ó–∞ –æ–±–ª–∞—á–∫–æ —á–µ—Ä–¥–∞—á–Ω–æ–µ\n",
      "–í –æ–∫–æ—à–∫–æ –≤–∏–¥–Ω–æ.\n",
      "–ò –∫—É–¥–∞ –± –Ω–∏ –∑–∞—à–µ–ª –≤–µ—á–µ—Ä,\n",
      "–ö–∞–∫ –æ–≥–æ–Ω–µ–∫ –≥–æ—Ä–∏—Ç, –∫–∞–∫ —Å–≤–µ—á–∫–∞ –≥–æ—Ä–∏—Ç,\n",
      "–¢–∞–º, –≤ –¥–æ–º–µ, –≥–¥–µ –∂–∏—Ç—å –Ω–∞–º –≤—Å–µ–º —Ç–µ–ø–µ—Ä—å –Ω–∞–¥–æ,\n",
      "–í –¥–æ–º–∏–∫–µ, –ø–æ–ª–Ω–æ–º —Ç–µ–ø–ª–∞ –∏ —Å–∏–ª,\n",
      "–û–Ω —Å –Ω–∞–º–∏ –æ–ø—è—Ç—å –Ω–∞ –ø–æ—Å–∏–¥–µ–ª–∫–∏\n",
      "–£ –∫–∞–º–∏–Ω–∞ —Å–∏–¥—è—Ç.\n",
      "–î–∏–≤—è—Ç—Å—è, —É–º–∏–ª—è—é—Ç—Å—è –¥–µ—Ç–≤–æ—Ä–∞\n",
      "–†–∞–∑–≥—É–ª—É –≤–µ—Å–µ–ª—ã—Ö —Ä—É–∫,\n",
      "–ò —à—É–º–Ω–æ —Å–º–µ—é—Ç—Å—è, –∑–≤–æ–Ω–∫–æ\n",
      "–†–µ–±–µ–Ω–∫—É –≥–æ—Ä–¥—ã–π —Å—Ç–∞–Ω;\n",
      "–ò –∂–∞—Ä–∫–æ –∏–º, –∏ –≤–µ—Å–µ–ª–æ,\n",
      "–ù–∞ —Å–æ–ª–µ–Ω–æ –±–æ—Ä–æ–Ω–∫–µ\n",
      "–í–∑–ª–∞—è—Ç—å –¥—Ä—É–≥ –¥—Ä—É–≥–∞, –ø–æ–∏–≥—Ä–∞—Ç—å.\n",
      "–î–∞ –¥–µ—Ç–∏ –∫—Ä—É–≥–æ–º —à—É–º—è—Ç,\n",
      "–ò –±–µ—Å–µ–¥–∞ —Å–≤–µ—Ç—Å–∫–∞—è –≤ –∫–æ–º–Ω–∞—Ç–µ \n",
      "–û—Ç –∏–∑–±—ã—Ç–∫–∞ –∫—Ä—É–∂–∏—Ç;\n",
      "–ò —à—É–º—è—Ç –≤–µ—Å–µ–ª–∏–µ–º –∏–≥—Ä–∞,\n",
      "–õ–∏—Ö–æ –∫–∞—Ç—è, –∫–æ–ª–µ—Å–æ–º —Å–∫–∞—á–µ—Ç,\n",
      "–ú–µ–∂ –≥–æ—Ä—Å—Ç—ã—Ö –∏–∑–± —Ç–µ—Å–Ω—è, -\n",
      "–ß—Ç–æ–± —à—É–º–µ–ª, –∫–∞–∫ –±–µ–ª–∫–∞, –≤–æ–¥–∏—á\n"
     ]
    }
   ],
   "source": [
    "text = \"–î–æ–∂–¥—å –∏–¥–µ—Ç \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=1.4,\n",
    "                        top_k=50,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff3ea4",
   "metadata": {},
   "source": [
    "# –ó–∞–¥–∞–Ω–∏–µ 2\n",
    "\n",
    "1)–æ–±—â–µ–µ: https://link.springer.com/article/10.1007/BF00279189 <br>\n",
    "    GPT-1:http://ceur-ws.org/Vol-2380/paper_102.pdf <br>\n",
    "    GPT-2:https://dl.acm.org/doi/pdf/10.1145/3460426.3463662 <br>\n",
    "    GPT-3: https://www.sciencedirect.com/science/article/pii/S2667325821002193<br>\n",
    "    \n",
    "2)\n",
    "–†–∞–∑–º–µ—Ä—ã –º–æ–¥–µ–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–ª–∏—Å—å –∑–∞ —Å—á–µ—Ç –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö Common Crawl ‚Äî —ç—Ç–æ –≤–µ–±-–∞—Ä—Ö–∏–≤, —Å–æ–±—Ä–∞–Ω–Ω—ã–π —Å 2011 –≥–æ–¥–∞ –∏ —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –ø–æ—á—Ç–∏ —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞ —Å–ª–æ–≤. –ß—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–¥–µ–ª–∞–ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ:\n",
    "> - –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∏ –≤–µ—Ä—Å–∏—é CommonCrawl (–≤–µ–±-–∞—Ä—Ö–∏–≤, —Å–æ–±—Ä–∞–Ω–Ω—ã–π —Å 2011 –≥–æ–¥–∞ –∏ —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –ø–æ—á—Ç–∏ —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞ —Å–ª–æ–≤);\n",
    "> - –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –Ω–µ—á–µ—Ç–∫—É—é –¥–µ–¥—É–±–ª–∏–∫–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–≤–Ω—É—Ç—Ä–∏) –∏ –º–µ–∂–¥—É –Ω–∞–±–æ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–∏–º–µ–Ω—è–µ–º–æ–≥–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è;\n",
    "> - –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –¥–æ–±–∞–≤–∏–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –∫–æ—Ä–ø—É—Å–∞ –≤ –Ω–∞–±–æ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: WebText; –∫–æ—Ä–ø—É—Å–∞ –∫–Ω–∏–≥ Books1 –∏ Books2; –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—É—é –í–∏–∫–∏–ø–µ–¥–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8285180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
