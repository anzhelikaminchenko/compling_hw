{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5154c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\howto\\anaconda3\\lib\\site-packages (4.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: requests in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\howto\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\howto\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14eb2f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - cudatoolkit=11.2\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/pytorch/win-64\n",
      "  - https://conda.anaconda.org/pytorch/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision cudatoolkit=11.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c34af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f174de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "    Running setup.py install for pytorch: started\n",
      "    Running setup.py install for pytorch: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\howto\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\howto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-iofw0n9r\\\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\howto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-iofw0n9r\\\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\howto\\AppData\\Local\\Temp\\pip-wheel-b03c9v1q'\n",
      "       cwd: C:\\Users\\howto\\AppData\\Local\\Temp\\pip-install-iofw0n9r\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\n",
      "  Complete output (5 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\howto\\AppData\\Local\\Temp\\pip-install-iofw0n9r\\pytorch_b5bc674ad8764c069e9d391db0c93729\\setup.py\", line 15, in <module>\n",
      "      raise Exception(message)\n",
      "  Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\howto\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\howto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-iofw0n9r\\\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\howto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-iofw0n9r\\\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\howto\\AppData\\Local\\Temp\\pip-record-sytxnr91\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\howto\\anaconda3\\Include\\pytorch'\n",
      "         cwd: C:\\Users\\howto\\AppData\\Local\\Temp\\pip-install-iofw0n9r\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\howto\\AppData\\Local\\Temp\\pip-install-iofw0n9r\\pytorch_b5bc674ad8764c069e9d391db0c93729\\setup.py\", line 11, in <module>\n",
      "        raise Exception(message)\n",
      "    Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\howto\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\howto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-iofw0n9r\\\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\howto\\\\AppData\\\\Local\\\\Temp\\\\pip-install-iofw0n9r\\\\pytorch_b5bc674ad8764c069e9d391db0c93729\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\howto\\AppData\\Local\\Temp\\pip-record-sytxnr91\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\howto\\anaconda3\\Include\\pytorch' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1d4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2306f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'gedichte.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a364927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howto\\anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Creating features from dataset file at \n",
      "Saving features into cached file cached_lm_GPT2Tokenizer_64_gedichte.txt [took 0.001 s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "# Создание датасета\n",
    "train_dataset = TextDataset( tokenizer=tokenizer,file_path=train_path,block_size=64, \n",
    "                            overwrite_cache=True)\n",
    "  \n",
    "# специальный класс который будет подавать в модель данные в нужном ей виде\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ed55e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments( \n",
    "    output_dir= \"./finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=100, \n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=32,  \n",
    "    gradient_accumulation_steps=16, \n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01521627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 512\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 22:58, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.12120740890502929, metrics={'train_runtime': 1392.8561, 'train_samples_per_second': 1.364, 'train_steps_per_second': 0.072, 'total_flos': 62056857600000.0, 'train_loss': 0.12120740890502929, 'epoch': 100.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3ed282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сияет небо и озаряется Луна.\n",
      "И звёзды светясь отражают всё прекрасное,\n",
      "В Мир свой приход озаряясь полной святостью.\n",
      "\n",
      "С добротой делитый, я жил\n",
      "Во знойных степях,\n",
      "В селениях юных,\n",
      "И было со мной так душевно,\n",
      "Что мог бы пожелать\n",
      "О смерти даже небожеский род!\n",
      "\n",
      "Рассказал я вам сон,\n",
      "Двум деткам на заметку пришитый\n",
      "И очень ему зацвенявшей,\n",
      "Палачей по пояс.\n",
      "Первый, как показалось глазам, замер,\n",
      "Вздохнув без отдыха. Едва живой,\n",
      "Проливший кровь, валялся старик во гробу,\n",
      "Двух детей уложив наземь.\n",
      "В тот же миг рядышком сомкнулся\n",
      "Рог с воинственным кличем: \"Вiдэс!\" - и мёртвым он впопыхах\n",
      "Двоих обезображил сталью.\n"
     ]
    }
   ],
   "source": [
    "text = \"Сияет небо\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=1.4,\n",
    "                        top_k=50,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4172ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Конец пути». Это отрывок из песни О. Уайльда \"Брат мой Алексей, не плачь\". На поле битвы человек встает и идёт к дому. Навстречу ему — Лиза, вся заляпанная мутью. На коленях стоит, причитая она. Спит она в избе рядом с ним. Лежал он один, как мёртвый, в избе. Спала она в избе, у Ивана Васильевича... Всё кругом затихло... Встал богатырь — и видит: перед ними стоит дом родной. Заплакал и обмер от жалости человек. Бросил он к ногам царь царей дары: рубаху да штаны отдал, велел слугам рубить с убитых, да жарить в печи...\n",
      "\n",
      "Через лес прошёл человек большой — большой! — и стал копать яму. Но не шелохнулись распоротые одежды. Из земли показались на свет сухие черви. Стал злодеи совокупляться — человек рыдал всё громче и свирепей. Наконец,\n"
     ]
    }
   ],
   "source": [
    "text = \"Конец пути\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=1.4,\n",
    "                        top_k=50,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c54060f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Дождь идет \n",
      "Между гор седыми\n",
      "И тающая сага\n",
      "За облачко чердачное\n",
      "В окошко видно.\n",
      "И куда б ни зашел вечер,\n",
      "Как огонек горит, как свечка горит,\n",
      "Там, в доме, где жить нам всем теперь надо,\n",
      "В домике, полном тепла и сил,\n",
      "Он с нами опять на посиделки\n",
      "У камина сидят.\n",
      "Дивятся, умиляются детвора\n",
      "Разгулу веселых рук,\n",
      "И шумно смеются, звонко\n",
      "Ребенку гордый стан;\n",
      "И жарко им, и весело,\n",
      "На солено боронке\n",
      "Взлаять друг друга, поиграть.\n",
      "Да дети кругом шумят,\n",
      "И беседа светская в комнате \n",
      "От избытка кружит;\n",
      "И шумят веселием игра,\n",
      "Лихо катя, колесом скачет,\n",
      "Меж горстых изб тесня, -\n",
      "Чтоб шумел, как белка, водич\n"
     ]
    }
   ],
   "source": [
    "text = \"Дождь идет \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=1.4,\n",
    "                        top_k=50,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff3ea4",
   "metadata": {},
   "source": [
    "1)общее: https://link.springer.com/article/10.1007/BF00279189 <br>\n",
    "    GPT-1:http://ceur-ws.org/Vol-2380/paper_102.pdf <br>\n",
    "    GPT-2:https://dl.acm.org/doi/pdf/10.1145/3460426.3463662 <br>\n",
    "    GPT-3: https://www.sciencedirect.com/science/article/pii/S2667325821002193<br>\n",
    "    \n",
    "2)\n",
    "Размеры модели значительно увеличились за счет набора данных Common Crawl — это веб-архив, собранный с 2011 года и состоящий из почти триллиона слов. Чтобы улучшить среднее качество наборов данных, разработчики сделали следующее:\n",
    "> - отфильтровали версию CommonCrawl (веб-архив, собранный с 2011 года и состоящий из почти триллиона слов);\n",
    "> - выполнили нечеткую дедубликацию на уровне документа (внутри) и между наборами данных, чтобы предотвратить избыточность и сохранить целостность валидационного набора данных, применяемого для оценки переобучения;\n",
    "> - для разнообразия добавили известные высококачественные эталонные корпуса в набор тренировочных данных: WebText; корпуса книг Books1 и Books2; англоязычную Википедию."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
