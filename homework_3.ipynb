{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c0a329",
   "metadata": {},
   "source": [
    "<h2>1. Доп. ранжирование по вероятности<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e491e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in c:\\users\\howto\\anaconda3\\lib\\site-packages (4.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c7916a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textdistance\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a90d1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=1000)\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "22e151d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    \n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    \n",
    "    return [(id2word[top], similarities[top]) for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ea0717fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    \n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f950fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    \n",
    "    return closest\n",
    "\n",
    "N = sum(vocab.values())\n",
    "\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N\n",
    "\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "46b3dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('солнце', 0.8333333333333334), ('соне', 0.8), ('донце', 0.8)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('сонце', X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "502d8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3fba25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=1, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "55fe1aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('солнце', 0.8333333333333334)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('сонце', X, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc27d09",
   "metadata": {},
   "source": [
    "<h2>2. Symspell<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4cc5cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk import sent_tokenize\n",
    "punctuation += \"«»—…“”\"\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "be153134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    return set(w for w in words if w in vocab)\n",
    "\n",
    "def edits1(word):\n",
    "    letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    return set(deletes)\n",
    "\n",
    "def edits2(word): \n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d934177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "\n",
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cf741959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "be2551b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'сонце'\n",
    "splits = [(word[:i], word[i:])    for i in range(len(word) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f8f47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1], get_closest_hybrid_match(pair[1], X, vec)[0][0])\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1\n",
    "    \n",
    "    if not i % 100:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7dcc6b",
   "metadata": {},
   "source": [
    "**очень долго работает**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6bf98700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490245122561281\n",
      "0.43711180124223603\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e181bbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'хочется'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correction('хочеться')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b530013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'привет'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correction('приветб')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0225bd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сегодня', 'седня', 'сеня'),\n",
       " ('вообще', 'ваще', 'аще'),\n",
       " ('кстати', 'кстате', 'кате'),\n",
       " ('очень', 'ооочень', 'очень'),\n",
       " ('что-то', 'что-то', 'тото'),\n",
       " ('как-то', 'както', 'като'),\n",
       " ('очень', 'оооочень', 'оооочень'),\n",
       " ('это', 'ето', 'то'),\n",
       " ('ничего', 'ничо', 'нио'),\n",
       " ('что-то', 'чтото', 'тото')]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(wt[0], wt[1], correction(wt[1])) for wt, _ in Counter(mistakes).most_common(10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
