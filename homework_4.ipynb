{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdf9b28",
   "metadata": {},
   "source": [
    "# Задание № 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fded281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a29af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92642831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "dvach = open('2ch_corpus.txt', encoding = 'UTF-8').read()\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n",
    "\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "\n",
    "sentences_dvach = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)][:-100]\n",
    "sentences_perplexity = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81a6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "trigrams_dvach = Counter()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    unigrams_dvach.update(sentence)\n",
    "    bigrams_dvach.update(ngrammer(sentence))\n",
    "    trigrams_dvach.update(ngrammer(sentence, n=3))\n",
    "    if i >4000:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2996d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = np.zeros((len(bigrams_dvach), \n",
    "                   len(unigrams_dvach)))\n",
    "\n",
    "id2word_dvach_1 = list(unigrams_dvach)\n",
    "word2id_dvach_1 = {word:i for i, word in enumerate(id2word_dvach_1)}\n",
    "\n",
    "id2word_dvach_2 = list(bigrams_dvach)\n",
    "word2id_dvach_2 = {word:i for i, word in enumerate(id2word_dvach_2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba3897fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef75006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = lil_matrix((len(bigrams_dvach), \n",
    "                   len(unigrams_dvach)))\n",
    "\n",
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "\n",
    "id2bigram_dvach = list(bigrams_dvach)\n",
    "bigram2id_dvach = {word:i for i, word in enumerate(id2bigram_dvach)}\n",
    "\n",
    "for ngram in trigrams_dvach:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = word1 + ' ' + word2\n",
    "\n",
    "    matrix_dvach[bigram2id_dvach[bigram], word2id_dvach[word3]] =  (trigrams_dvach[ngram]/\n",
    "                                                                     bigrams_dvach[bigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff0981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, word2id, n=200, start ='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = word2id['<start>']\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen = np.random.choice(list(range(matrix.shape[1])), p=matrix[current_idx].toarray()[0])\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen = word2id['<start>']\n",
    "        current_idx = chosen\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6370189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "скажи \n",
      "\n",
      " снова ты при мб и прочих лулзов от звука в отправляется говно ещё драфт ставите для ссылка порнотред в отправляется непотребство прочее и прочих клованов что ffmpeg файлов кодеки плеер установить воспроизведения и прочих лулзов от звука в отправляется непотребство прочее и прочих лулзов от звука в отправляется непотребство прочее и прочих лулзов от звука в отправляется говно ещё драфт ставите для ссылка порнотред в отправляется непотребство прочее и прочих клованов что ffmpeg файлов кодеки плеер установить воспроизведения и прочих аутистов \n",
      "\n",
      " дохуя стерто ара на видео o поиска для ссылка порнотред в отправляется непотребство прочее и прочих аутистов \n",
      "\n",
      " лол лиц буду дальше без с вечно востребованного иди клона то для ссылка порнотред в отправляется говно ещё драфт ставите для ссылка порнотред в отправляется непотребство прочее и прочих лулзов от звука в отправляется говно ещё драфт ставите для ссылка порнотред в отправляется говно ещё драфт ставите для ссылка порнотред в отправляется непотребство прочее и прочих лулзов от звука в отправляется непотребство прочее и прочих лулзов от звука в отправляется непотребство прочее и прочих аутистов \n",
      "\n",
      " врачи особенно 2 свой опенинг как zsh on использования 10240 webm ищем клик кадр видео o поиска для ссылка порнотред в отправляется\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2word_dvach, word2id_dvach, n=200).replace('<end>', '\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3da1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(probas):\n",
    "    p = np.exp(np.sum(probas))\n",
    "    N = len(probas)\n",
    "    \n",
    "    return p**(-1/N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f5c7393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> <start> анимублядский webm-треддля приличных анимублядей и прочих аутистов <end> 1.0 \n",
      "\n",
      "<start> <start> безграмотное быдло с дубляжом войсовером порнографией и котиками советы мерзких мокрописечников вниманиебляди всех видов и прочее непотребство отправляется в порнотред ссылка для поиска с o уса видео сохраняем кадр правый клик по видео и ищем его на для воспроизведения webm с 10-битным цветом нужно установить плагин vlc и отключить встроенный в браузер плеер media <end> 1.0 \n",
      "\n",
      "<start> <start> webm <end> 1.0 \n",
      "\n",
      "<start> <start> enabled false в firefox о кодировании webm доступные кодеки — vp 8 и vp 9 для видео vorbis и opus для звука максимальный размер файла — 10240 кб всех файлов в посте — около 40 мб <end> 1.0 \n",
      "\n",
      "<start> <start> делать webm можно научиться в вики треда там находится подробная информация о выборе и настройке кодеков на примерах использования консольных утилит ffmpeg vpxenc и mkvmerge <end> 1.0 \n",
      "\n",
      "<start> <start> неочевидные моменты— libvorbis при указании битрейта b a работает в режиме cbr постоянный битрейт и это портит качество звука для режима vbr вместо битрейта надо указывать качество q a параметр vbr on работает только для opus а — в webm ки не нужно включать софтсаб в формате webvtt ffmpeg это делает по умолчанию при наличии сабов в контейнере отключается параметром sn во-первых это бесполезно для его отображения на странице должен быть специальный код а во-вторых от этого ролики не воспроизводятся в firefox <end> 2.0 \n",
      "\n",
      "<start> <start> программы и их документация фронтенды к ffmpeg для кодирования вебмок cli бидон zsh дотнет дотнет оп-паста посоны поделитесь ссылкой на ютуб-версию этого шебм <end> 1.0 \n",
      "\n",
      "<start> <start> побольше тебе стандопавера бро <end> 1.0 \n",
      "\n",
      "<start> <start> перекатился <end> 1.0 \n",
      "\n",
      "<start> <start> благословил <end> 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences_dvach[:10]:\n",
    "    prob = []\n",
    "    for ngram in ngrammer(sent, 3):\n",
    "        word1, word2, word3 = ngram.split()\n",
    "        bigram = word1 + ' '+word2\n",
    "    if ngram in trigrams_dvach and bigram in bigrams_dvach:\n",
    "            prob.append(np.log(trigrams_dvach[ngram] / bigrams_dvach[bigram]))\n",
    "  \n",
    "    print(\" \".join(sent), perplexity(prob), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad06a4",
   "metadata": {},
   "source": [
    "# Задание № 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4b42f",
   "metadata": {},
   "source": [
    "1) Существует два способа (указанные в сатье), которыми можно бороться с проблемой несловарных слов (\"UNK\"):\n",
    "1. Выбрать фиксированный словарь;\n",
    "2. С помощью вычисления частоты (а именно - малочастотности) заменять их на UNK.\n",
    "\n",
    "2) Чтобы словам, которые имеются в слоаре, но находятся в тестовом наборе в невидимом контексте (например, они появляются после слова, после которого они никогда не появлялись при обучении), не приписывалась нулевая вероятность, им добавляется какая-то часть вероятности более частотных слов. Эта модификация называется сглаживанием или дисконтированием (smoothing or discounting)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
